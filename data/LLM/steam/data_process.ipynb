{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import demjson3\n",
    "from tqdm import tqdm\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../steam_games.json', 'r') as f: # name of game\n",
    "    metadata = [eval(json.loads(demjson3.encode(line))) for line in f]\n",
    "\n",
    "\n",
    "with open('../steam_new.json') as f: # interaction\n",
    "    reviews = [eval(json.loads(demjson3.encode(line))) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set()\n",
    "items = set()\n",
    "for review in tqdm(reviews):\n",
    "    users.add(review['username'])\n",
    "    items.add(review['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2id = dict()\n",
    "count = 0\n",
    "for item in items:\n",
    "    item2id[item] = count\n",
    "    count += 1\n",
    "print(len(users), len(items), len(reviews), len(reviews) / (len(users) * len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_title = {}\n",
    "id_item = {}\n",
    "cnt = 0\n",
    "for meta in tqdm(metadata):\n",
    "    if 'title' in meta.keys() and 'id' in meta.keys() and len(meta['title']) > 1: # remove the item without title\n",
    "        id_title[meta['id']] = meta['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "user_num_dict = defaultdict(int)\n",
    "item_num_dict = defaultdict(int)\n",
    "for review in tqdm(reviews):\n",
    "    user = review['username']\n",
    "    item = review['product_id']\n",
    "\n",
    "    user_num_dict[user] += 1\n",
    "    item_num_dict[item] += 1\n",
    "\n",
    "\n",
    "user_nocold = []\n",
    "item_nocold = []\n",
    "for user in user_num_dict.keys():\n",
    "    if user_num_dict[user] >= 20:\n",
    "        user_nocold.append(user)\n",
    "\n",
    "for item in item_num_dict.keys():\n",
    "    if item_num_dict[item] >= 20:\n",
    "        item_nocold.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(user_nocold), len(item_nocold))\n",
    "\n",
    "user_nocold = user_nocold[:int(len(user_nocold)*0.3)]\n",
    "item_nocold = item_nocold[:int(len(user_nocold)*0.3)]\n",
    "\n",
    "user_nocold = set(user_nocold)\n",
    "item_nocold = set(item_nocold)\n",
    "\n",
    "print(len(user_nocold), len(item_nocold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = dict()\n",
    "cc = 0\n",
    "n_interaction = 0\n",
    "for review in tqdm(reviews):\n",
    "    user = review['username']\n",
    "    if 'product_id' not in review:\n",
    "        break\n",
    "    item = review['product_id']\n",
    "    if item not in id_title:\n",
    "        continue\n",
    "    if user not in user_nocold:\n",
    "        continue\n",
    "    if item not in item_nocold:\n",
    "        continue\n",
    "    if review['product_id'] not in id_item:\n",
    "        id_item[review['product_id']] = cnt\n",
    "        cnt += 1\n",
    "    # if 'overall' not in review:\n",
    "    #     continue\n",
    "    if 'date' not in review:\n",
    "        continue\n",
    "    if user not in users:\n",
    "        users[user] = {\n",
    "            'items': [],\n",
    "            'timestamps': [],\n",
    "            'reviews': []\n",
    "        }\n",
    "    if item not in users[user]['items']:\n",
    "        users[user]['items'].append(item)\n",
    "        users[user]['timestamps'].append(review['date'])\n",
    "        n_interaction += 1\n",
    "    else:\n",
    "        cc += 1\n",
    "\n",
    "\n",
    "print(cc, n_interaction)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2title_no_cold = {}\n",
    "for meta in tqdm(metadata):\n",
    "    if 'title' in meta.keys() and 'id' in meta.keys() and meta['id'] in item_nocold: # remove the item without title\n",
    "        item2title_no_cold[meta['id']] = meta['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(item2title_no_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2id_no_cold = {}\n",
    "cnt = 0\n",
    "\n",
    "for item in item2title_no_cold.keys():\n",
    "    item2id_no_cold[item] = cnt\n",
    "    cnt += 1\n",
    "\n",
    "print(item2id_no_cold)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "interactions = []\n",
    "B = []\n",
    "for key in tqdm(users.keys()):\n",
    "    items = users[key]['items']\n",
    "    timestamps = users[key]['timestamps']\n",
    "    all = list(zip(items, timestamps))\n",
    "    res = sorted(all, key=lambda x: int(x[-1].replace(\"-\", \"\")))\n",
    "    items, timestamps = zip(*res)\n",
    "    items, timestamps = list(items), list(timestamps)\n",
    "    users[key]['items'] = items\n",
    "    users[key]['item_ids'] = [item2id_no_cold[x] for x in items]\n",
    "    users[key]['item_titles'] = [item2title_no_cold[x] for x in items]\n",
    "    users[key]['timestamps'] = [t.replace(\"-\", \"\") for t in timestamps]\n",
    "    users[key]['timestamps_all'] = timestamps[0].replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_sorted = sorted(users.items(), key=lambda x: int(x[1]['timestamps_all']))\n",
    "train_sessions = users_sorted[:int(len(users_sorted) * 0.8)]\n",
    "val_sessions = users_sorted[int(len(users_sorted) * 0.8):int(len(users_sorted) * 0.9)]\n",
    "test_sessions = users_sorted[int(len(users_sorted) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_item = len(item2id_no_cold.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9550/9550 [00:00<00:00, 37636.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_interactions = []\n",
    "\n",
    "for kv in tqdm(train_sessions):\n",
    "    k = kv[0]\n",
    "    v = kv[1]\n",
    "    if len(v['items']) > 10:\n",
    "        for i in range(min(10, len(v['items']) - 1), len(v['items'])):\n",
    "            st = max(i - 10, 0)\n",
    "            train_interactions.append([k, v['items'][st: i], v['items'][i], v['item_ids'][st: i], v['item_ids'][i], v['item_titles'][st: i], v['item_titles'][i], int(v['timestamps'][i])])\n",
    "    else:\n",
    "        temp = [pad_item] * (10-len(v['items']))\n",
    "        itemlist = v['item_ids'][:]\n",
    "        itemlist.extend(temp)\n",
    "        train_interactions.append([k, v['items'][:], v['items'][-1], itemlist, v['item_ids'][-1], v['item_titles'][:], v['item_titles'][-1], int(v['timestamps'][-1])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1194/1194 [00:00<00:00, 49086.96it/s]\n"
     ]
    }
   ],
   "source": [
    "val_interactions = []\n",
    "\n",
    "for kv in tqdm(val_sessions):\n",
    "    k = kv[0]\n",
    "    v = kv[1]\n",
    "    if len(v['items']) > 10:\n",
    "        for i in range(min(10, len(v['items']) - 1), len(v['items'])):\n",
    "            st = max(i - 10, 0)\n",
    "            val_interactions.append([k, v['items'][st: i], v['items'][i], v['item_ids'][st: i], v['item_ids'][i], v['item_titles'][st: i], v['item_titles'][i], int(v['timestamps'][i])])\n",
    "    else:\n",
    "        temp = [pad_item] * (10-len(v['items']))\n",
    "        itemlist = v['item_ids'][:]\n",
    "        itemlist.extend(temp)\n",
    "        val_interactions.append([k, v['items'][:], v['items'][-1], itemlist, v['item_ids'][-1], v['item_titles'][:], v['item_titles'][-1], int(v['timestamps'][-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1194/1194 [00:00<00:00, 56391.30it/s]\n"
     ]
    }
   ],
   "source": [
    "test_interactions = []\n",
    "\n",
    "for kv in tqdm(test_sessions):\n",
    "    k = kv[0]\n",
    "    v = kv[1]\n",
    "    if len(v['items']) > 10:\n",
    "        for i in range(min(10, len(v['items']) - 1), len(v['items'])):\n",
    "            st = max(i - 10, 0)\n",
    "            test_interactions.append([k, v['items'][st: i], v['items'][i], v['item_ids'][st: i], v['item_ids'][i], v['item_titles'][st: i], v['item_titles'][i], int(v['timestamps'][i])])\n",
    "    else:\n",
    "        temp = [pad_item] * (10-len(v['items']))\n",
    "        itemlist = v['item_ids'][:]\n",
    "        itemlist.extend(temp)\n",
    "        test_interactions.append([k, v['items'][:], v['items'][-1], itemlist, v['item_ids'][-1], v['item_titles'][:], v['item_titles'][-1], int(v['timestamps'][-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_interactions = []\n",
    "\n",
    "for kv in tqdm(test_sessions):\n",
    "    k = kv[0]\n",
    "    v = kv[1]\n",
    "\n",
    "    if len(v['items']) > 10:\n",
    "        i = len(v['items']) - 1\n",
    "\n",
    "        st = max(i - 10, 0)\n",
    "        Test_interactions.append([k, v['items'][st: i], v['items'][i], v['item_ids'][st: i], v['item_ids'][i], v['item_titles'][st: i], v['item_titles'][i], int(v['timestamps'][i])])\n",
    "\n",
    "    else:\n",
    "        temp = [pad_item] * (10-len(v['items']))\n",
    "        itemlist = v['item_ids'][:]\n",
    "        itemlist.extend(temp)\n",
    "        Test_interactions.append([k, v['items'][:], v['items'][-1], itemlist, v['item_ids'][-1], v['item_titles'][:], v['item_titles'][-1], int(v['timestamps'][-1])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_interactions[0])\n",
    "print(train_interactions[1])\n",
    "print(val_interactions[0])\n",
    "print(val_interactions[1])\n",
    "print(test_interactions[0])\n",
    "print(test_interactions[1])\n",
    "print(Test_interactions[0])\n",
    "print(Test_interactions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing files\n",
    "import csv\n",
    "\n",
    "with open('./train.csv', 'w') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    csvwriter.writerows(train_interactions[:])\n",
    "\n",
    "with open('./val.csv', 'w') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    csvwriter.writerows(val_interactions[:])\n",
    "\n",
    "with open('./test.csv', 'w') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    csvwriter.writerows(test_interactions[:])\n",
    "\n",
    "\n",
    "with open('./Test.csv', 'w') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    csvwriter.writerows(Test_interactions[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./id2name.txt', 'w') as f:\n",
    "    for i in item2id_no_cold.keys():\n",
    "        f.write(str(item2id_no_cold[i]))\n",
    "        f.write('::')\n",
    "        f.write(item2title_no_cold[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    x = x[1:-1]\n",
    "    x = x.split(',')\n",
    "    x = [int(i) for i in x]\n",
    "    return x\n",
    "\n",
    "def str2list2(x):\n",
    "    x = x[1:-1]\n",
    "    x = x.split(',')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_raw = pd.read_csv('./train.csv')\n",
    "\n",
    "train_data_raw\n",
    "\n",
    "train_data = train_data_raw[['item_asins', 'history_item_id', 'item_id']]\n",
    "\n",
    "train_data.columns = ['seq_unpad', 'seq', 'next']\n",
    "\n",
    "train_data['seq'] = train_data['seq'].apply(lambda x: str2list(x))\n",
    "train_data['seq_unpad'] = train_data['seq_unpad'].apply(lambda x: str2list2(x))\n",
    "\n",
    "train_data['next'] = train_data['next'].apply(lambda x: int(x))\n",
    "\n",
    "train_data['len_seq'] = train_data['seq_unpad'].apply(lambda x: len(x))\n",
    "min(train_data['len_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_raw = pd.read_csv('./val.csv')\n",
    "\n",
    "val_data_raw\n",
    "\n",
    "val_data = val_data_raw[['item_asins', 'history_item_id', 'item_id']]\n",
    "\n",
    "val_data.columns = ['seq_unpad', 'seq', 'next']\n",
    "\n",
    "val_data['seq'] = val_data['seq'].apply(lambda x: str2list(x))\n",
    "val_data['seq_unpad'] = val_data['seq_unpad'].apply(lambda x: str2list2(x))\n",
    "\n",
    "val_data['next'] = val_data['next'].apply(lambda x: int(x))\n",
    "\n",
    "val_data['len_seq'] = val_data['seq_unpad'].apply(lambda x: len(x))\n",
    "min(val_data['len_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = pd.read_csv('./test.csv')\n",
    "\n",
    "test_data_raw\n",
    "\n",
    "test_data = test_data_raw[['item_asins', 'history_item_id', 'item_id']]\n",
    "\n",
    "test_data.columns = ['seq_unpad', 'seq', 'next']\n",
    "\n",
    "test_data['seq'] = test_data['seq'].apply(lambda x: str2list(x))\n",
    "test_data['seq_unpad'] = test_data['seq_unpad'].apply(lambda x: str2list2(x))\n",
    "\n",
    "test_data['next'] = test_data['next'].apply(lambda x: int(x))\n",
    "\n",
    "test_data['len_seq'] = test_data['seq_unpad'].apply(lambda x: len(x))\n",
    "min(test_data['len_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_raw = pd.read_csv('./Test.csv')\n",
    "\n",
    "Test_data_raw\n",
    "\n",
    "Test_data = Test_data_raw[['item_asins', 'history_item_id', 'item_id']]\n",
    "\n",
    "Test_data.columns = ['seq_unpad', 'seq', 'next']\n",
    "\n",
    "Test_data['seq'] = Test_data['seq'].apply(lambda x: str2list(x))\n",
    "Test_data['seq_unpad'] = Test_data['seq_unpad'].apply(lambda x: str2list2(x))\n",
    "\n",
    "Test_data['next'] = Test_data['next'].apply(lambda x: int(x))\n",
    "\n",
    "Test_data['len_seq'] = Test_data['seq_unpad'].apply(lambda x: len(x))\n",
    "min(Test_data['len_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_dic = {'seq_size':[10],'item_num':[pad_item]}\n",
    "data_statis = pd.DataFrame(data=static_dic)\n",
    "\n",
    "train_data = train_data[['seq', 'next', 'len_seq']]\n",
    "val_data = val_data[['seq', 'next', 'len_seq']]\n",
    "test_data = test_data[['seq', 'next', 'len_seq']]\n",
    "Test_data = Test_data[['seq', 'next', 'len_seq']]\n",
    "\n",
    "train_data.to_pickle('./train_data.df')\n",
    "val_data.to_pickle('./val_data.df')\n",
    "test_data.to_pickle('./ttest_data.df')\n",
    "Test_data.to_pickle('./Test_data.df')\n",
    "data_statis.to_pickle('./data_statis.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL = train_data[\"seq\"].apply(lambda x: len(x))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for k in LL:\n",
    "    if k == 9:\n",
    "        print(i)\n",
    "\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
